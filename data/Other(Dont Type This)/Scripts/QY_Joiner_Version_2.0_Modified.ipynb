{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import arcpy\n",
    "arcpy.env.overwriteOutput = True\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "from dbfpy import dbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TotalList = []; ReferList = []; R_ReferList = []; iterator = 0; i = 0\n",
    "def get_imme_subF(a_dir):    #Given a path, return a list of all immediate sub-directory's list\n",
    "    return [name for name in os.listdir(a_dir)\n",
    "            if os.path.isdir(os.path.join(a_dir, name))]\n",
    "def go_deep(level, RootPath):  #Given a root path, go deep a given level of directory, and return a list of all immediate sub-directory's list\n",
    "    for i in range(level):\n",
    "        RootPath = os.path.join(RootPath, get_imme_subF(RootPath)[0])\n",
    "    return get_imme_subF(RootPath)\n",
    "def split_check(String1, String2, check_location):#Check if a pair of string(filename)'s number X's element is equal or not\n",
    "    list1 = String1.split(\".\")\n",
    "    list2 = String2.split(\".\")\n",
    "    S1part = list1[0].split(\"_\")[check_location-1]\n",
    "    S2part = list2[0].split(\"_\")[check_location-1]\n",
    "    return S1part == S2part\n",
    "def dbf_to_csv(out_table):#Input a dbf, output a csv\n",
    "    csv_fn = out_table[:-4]+ \".csv\" #Set the table as .csv format\n",
    "    with open(csv_fn,'wb') as csvfile: #Create a csv file and write contents from dbf\n",
    "        in_db = dbf.Dbf(out_table)\n",
    "        out_csv = csv.writer(csvfile)\n",
    "        names = []\n",
    "        for field in in_db.header.fields: #Write headers\n",
    "            names.append(field.name)\n",
    "        out_csv.writerow(names)\n",
    "        for rec in in_db: #Write records\n",
    "            out_csv.writerow(rec.fieldData)\n",
    "        in_db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CSV_FilePath_SS = str(raw_input(\"Please provide the immediate parent file path to your ACS & DEC csv files:\" + \n",
    "\"\\n\\n\" + \"For example: G:\\Share\\GEOG6307\\Grossman, this path has two folders: ACS and DEC\"+\"\\n\\n\"\n",
    "+ \"This is the most important path required in this program, be very careful\" + \"\\n\\n>>>\"))# GGG等有了Tkinter之后\n",
    "print \"Changing current working directory to the path where tables located\"\n",
    "os.chdir(CSV_FilePath_SS)\n",
    "CSV_FilePath = os.getcwd()\n",
    "RootPath = CSV_FilePath\n",
    "VariableCategoryList = go_deep(2, CSV_FilePath)\n",
    "DatasetList = get_imme_subF(RootPath)\n",
    "# print back file path to user\n",
    "print \"\\n\" + \"File Path:\" + \"\\n\" + CSV_FilePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Which data category interests you?\" + \"\\n\"#Get category, by reference number\n",
    "for i in range(len(VariableCategoryList)):\n",
    "    print \"Type %s for \"%(str(i+1)) + VariableCategoryList[i] + \"\\n\"\n",
    "while True:\n",
    "    try:\n",
    "        CategoryDecision = str(raw_input(\"enter here, only numbers>>>>>>>\"))\n",
    "        Category = VariableCategoryList[int(CategoryDecision)-1]\n",
    "        break\n",
    "    except ValueError:\n",
    "        print \"That was not a valid number. Try again, please type in a number this time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Here is all the dataset available:\"#Get dataset name by user typed, will restart to record if the dataset name is not right\n",
    "for i in range(len(DatasetList)):\n",
    "    iplus = i + 1\n",
    "    print \"Dataset \" + str(iplus) + \":  \" + DatasetList[i]\n",
    "while True:\n",
    "    Dataset = str(raw_input(\n",
    "        \"\\nWhich data set interests you?\" + \"\\n\\n\"\n",
    "        \"Type ACS for American Community Survey\" + \"\\n\"\n",
    "        \"Type DEC for Decennial Census\" + \"\\n\\n> \"))\n",
    "    TrF = Dataset in DatasetList\n",
    "    if TrF == False:\n",
    "        print \"The dataset you entered is not a valid one, please enter again\"\n",
    "    else:\n",
    "        break\n",
    "CSV_FilePath = os.path.join(CSV_FilePath, Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Which %s year interests you?\"%(Dataset)#Get year by user typed, if the year is not correct if will restart to record year\n",
    "YearList = get_imme_subF(CSV_FilePath)\n",
    "for y in YearList:\n",
    "    print \"Type %s for 20%s\"%(y, y)\n",
    "while True:\n",
    "    YearDecision = raw_input(\"enter here, only numbers>>>>>>>\")\n",
    "    TrF2 = YearDecision in YearList\n",
    "    if TrF2 == False:\n",
    "        print \"The year you entered is not a valid one, please enter again, only two digit number\"\n",
    "    else:\n",
    "        break\n",
    "CSV_FilePath = os.path.join(CSV_FilePath, YearDecision)\n",
    "CSV_FilePath = os.path.join(CSV_FilePath, Category)# This is the path stored the requested csv\n",
    "print \"Grabing CSV from  \" + CSV_FilePath\n",
    "os.chdir(CSV_FilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Namelist = sorted(os.listdir(CSV_FilePath))#Get the variable name and description, get rid of all the variable start with \"margin\n",
    "for Index, NamePart in enumerate(Namelist):# of error\"\n",
    "    if Index + 1 == len(Namelist):\n",
    "            break\n",
    "    else:\n",
    "        Meta = NamePart\n",
    "        Ann = Namelist[(Index + 1)]\n",
    "        if split_check(Meta, Ann, 4) == False:\n",
    "            print \"There is a mismatch between Meta and Ann csv, here is the Meta file name: \"+\"\\n\"+Meta\n",
    "            print \"Skipping this pair of csv\"\n",
    "            continue\n",
    "        else:\n",
    "            MetaPd = pd.read_csv(Meta)\n",
    "            AnnPd = pd.read_csv(Ann)\n",
    "            GEOid_List = MetaPd[\"GEO.id\"].tolist()[2:]\n",
    "            id_List = MetaPd[\"Id\"].tolist()[2:]\n",
    "            GEOid_id_Dict = dict(zip(GEOid_List,id_List))\n",
    "            for key, val in GEOid_id_Dict.items():\n",
    "                if \"Margin of Error\" in val:\n",
    "                    del GEOid_id_Dict[key]\n",
    "            TotalList.append([Ann, GEOid_id_Dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"finished grabing the csv\" + \"\\n\" + \"Here is all the data avaible with explanation:\"\n",
    "for pair in TotalList:# Each pair represent a pair of csv\n",
    "    Ann_R = pair[0]# Ann_R as Ann really used\n",
    "    Identifier = Ann_R.split(\".\")[0].split(\"_\")[3]\n",
    "    G_I_Dict = pair[1]\n",
    "    for key, val in G_I_Dict.items():\n",
    "        iterator += 1\n",
    "        print str(iterator) + \": \" + Identifier + \"_\" + key + \"------\" + val + \"\\n\"\n",
    "        ReferList.append([iterator, Ann_R, key, val])\n",
    "while True:\n",
    "    print \"\"\"Choose a variable by the index number, for example:\\n7: DP03_HC01_VC127------\n",
    "    Estimate; HEALTH INSURANCE COVERAGE - Civilian noninstitutionalized population\\nIf you want to choose this variable, \n",
    "    simply type in 7. Now please type in the number based on all the variable provided above.\"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            ReferNum = raw_input(\"Enter here>>>>>>>>>>>\")#Get the variable by user typed number\n",
    "            SelectedComb = ReferList[int(ReferNum)-1]\n",
    "            break\n",
    "        except ValueError:\n",
    "            print \"That was not a valid number. Try again, please type in a number this time\"\n",
    "    OwnName = raw_input(\"\\n\" + \"Please type in your name for this variable, no more than 10 characters\" + \"\\n\"+\n",
    "                       \"If you want to keep the original name, type 0 >>>\")\n",
    "    if len(OwnName) > 10:\n",
    "        print \"Your name is more than 10 characters, this program automatically truncated the extra characters\"\n",
    "        OwnName = OwnName[0:10]\n",
    "    SelectedComb.append(OwnName)\n",
    "    R_ReferList.append(SelectedComb)\n",
    "    finished = raw_input(\"***************************************\" + \"\\n\\n\" +\n",
    "        \"Would you Like to select more variables in this specific dataset-year-categories combination?\\nType 1 for Yes\\nType 2 for No\\n> \")\n",
    "    if finished == \"1\":\n",
    "        continue      \n",
    "    if finished == \"2\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Joined_Pd = pd.DataFrame()\n",
    "i = 0\n",
    "for R_list in R_ReferList:\n",
    "    Ann_RR = R_list[1]\n",
    "    Ann_ID = R_list[2]\n",
    "    OwnName_2 = R_list[4]\n",
    "    Ann_Pd = pd.read_csv(Ann_RR)\n",
    "    Ann_Pd = Ann_Pd.loc[1:, [\"GEO.id\", Ann_ID]]\n",
    "    if OwnName_2 != \"0\":\n",
    "        Ann_Pd.columns = [\"GEO.id\", OwnName_2]\n",
    "    if i == 0:\n",
    "        Joined_Pd = Ann_Pd\n",
    "        i += 1\n",
    "    else:\n",
    "        Joined_Pd = Joined_Pd.merge(Ann_Pd, how = 'outer', on=\"GEO.id\")\n",
    "        i += 1\n",
    "print \"Here is your selected variable/variables, with its corresponding GeoId\"\n",
    "Joined_Pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DC_Shp = RootPath + \"\\\\Other(Dont Type This)\\\\ShapeFiles\" + \"\\\\DC_Census.shp\"#This is the madatory way to grab original shp\n",
    "DC_Shp_dbf = DC_Shp[:-4] + \".dbf\"\n",
    "Output_name = raw_input(\"Please type in the name of the folder where store the joined shp and description of variables\")#Get folder name\n",
    "hms = time.strftime(\"%H:%M:%S\")\n",
    "dmy = time.strftime(\"%d/%m/%Y\")#Get the current time and append it to folder name\n",
    "hms_list = hms.split(\":\")\n",
    "dmy_list = dmy.split(\"/\")\n",
    "Folder_Path=RootPath+\"\\\\Other(Dont Type This)\\\\Output\"+\"\\\\\"+Output_name+\"_\"+hms_list[0]+\"H\"+hms_list[1]+\"M\"+hms_list[2]+\"S\"+dmy_list[0]+\"D\"+dmy_list[1]+\"M\"+dmy_list[2]+\"Y\"\n",
    "os.mkdir(Folder_Path)\n",
    "D_txt = open(Folder_Path+\"\\\\Variable_Description.txt\", \"w\")#Creat a variable description txt in the output folder\n",
    "for R_list_2 in R_ReferList:\n",
    "    Change_name = R_list_2[4]\n",
    "    D_txt.write(\"The original variable number in CSV:   \" + str(R_list_2[0])+\"\\n\")\n",
    "    D_txt.write(\"The associated CSV name:   \" + R_list_2[1]+\"\\n\")\n",
    "    D_txt.write(\"The orignial variable name:   \" + R_list_2[2]+\"\\n\")\n",
    "    if Change_name == \"0\":\n",
    "        D_txt.write(\"The user-defined variable name:   None\"+\"\\n\")\n",
    "    else:\n",
    "        D_txt.write(\"The user-defined variable name:   \" + Change_name+\"\\n\")\n",
    "    D_txt.write(\"The explanation of the variable:   \" + R_list_2[3])\n",
    "    D_txt.write(\"\\n\\n\")\n",
    "D_txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Shp_name = raw_input(\"Last request: please type in the desired shapefile name, don't include .shp, no character as:\" + \n",
    "                    \"\\\\ or / or : or * or ? or \\\" or < or > or |\" + \"\\n>>>>>>>>>>>>>>>>\")\n",
    "arcpy.CopyFeatures_management(DC_Shp, Folder_Path+\"\\\\\"+Shp_name)#Copy a new shp to output folder from original one\n",
    "Copied_Shp = Folder_Path+\"\\\\\"+Shp_name+\".shp\"\n",
    "arcpy.TableToTable_conversion(DC_Shp_dbf, Folder_Path, \"Shp_original.csv\")#Grab the ori shp-dbf and covnert to csv(actually still dbf)\n",
    "Shp_csv = Folder_Path + \"\\\\Shp_original.csv\"\n",
    "Joined_shp_csv = Folder_Path + \"\\\\Shp_Joined_variable.csv\"\n",
    "dbf_to_csv(Folder_Path+\"\\\\Shp_original.dbf\")#Use self-defined function to change dbf to csv\n",
    "Shp_csv_pd = pd.read_csv(Shp_csv)#read csv as dataframe\n",
    "Shp_pd_lj = Shp_csv_pd.merge(Joined_Pd, how=\"left\", left_on=\"GEO_ID\", right_on=\"GEO.id\")#Left join the csv-dataframe with variable df\n",
    "Shp_pd_lj = Shp_pd_lj.rename(columns = {\"GEO_ID\":\"GEO_ID_2\"})#rename the joined df column so that it won't have same name in the future\n",
    "cols = [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "Shp_pd_lj.drop(Shp_pd_lj.columns[cols],axis=1,inplace=True)#Drop uneeded columns, only leave Geoid, and variables\n",
    "Shp_pd_lj.to_csv(Joined_shp_csv, index=False)\n",
    "arcpy.TableToTable_conversion(Joined_shp_csv, Folder_Path, \"Joined_variables.dbf\")# Convert the joined-modified df to dbf\n",
    "arcpy.JoinField_management(Copied_Shp,\"GEO_ID\", Folder_Path + \"\\\\Joined_variables.dbf\", \"GEO_ID_2\")#Join the dbf with new shp\n",
    "print \"Finished\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#arcpy.TableToTable_conversion(Folder_Path+\"\\\\Joined_variables.csv\", Folder_Path, \"Joined_variables.dbf\")\n",
    "#CensusLyr = arcpy.JoinField_management(CensusLyr,\"GEO_ID\", Folder_Path + \"\\\\Joined_variables.dbf\", \"GEO_id\")\n",
    "#DataYearCate = Dataset + YearDecision + Category\n",
    "#del Shp_pd_lj[\"GEO.id\"]\n",
    "#CensusLyr = arcpy.MakeFeatureLayer_management(DC_Shp, Folder_Path+\"\\\\censusLayer.lyr\")\n",
    "#arcpy.CopyFeatures_management(CensusLyr, Folder_Path + \"\\\\\" + Shp_name + \".shp\")\n",
    "#CensusLyr = arcpy.JoinField_management(CensusLyr,\"GEO_ID\", Folder_Path + \"\\\\Joined_variables.dbf\", \"GEO_id\")\n",
    "#del Shp_pd_lj[\"GEO.id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
